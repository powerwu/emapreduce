# 存储说明

本文介绍E-MapReduce集群中数据存储相关的信息，包括磁盘角色、云盘、本地盘和OSS。

## 磁盘角色

在E-MapReduce集群中，实例节点上有系统盘和数据盘两种角色的磁盘，系统盘用于安装操作系统，数据盘用于保存数据。系统盘默认都是一块，而数据盘可以有很多块（当前每个实例节点挂载上限为16块）。每块磁盘的配置、类型和容量都可以不同。

E-MapReduce默认使用ESSD云盘作为集群的系统盘，Master实例默认挂载1块云盘作为数据盘、Core实例默认挂载4块云盘作为数据盘。

## 云盘与本地盘

E-MapReduce集群支持使用如下两种类型的磁盘来存储数据：

-   云盘

    包括SSD云盘、高效云盘和ESSD云盘。磁盘不直接挂载在本地的计算节点上，而是通过网络访问远端的一个存储节点。每一份数据在后端都有两个实时备份，一共三份数据。当一份数据损坏时（磁盘损坏，不是用户自己业务上的破坏），E-MapReduce会自动使用备份数据进行恢复。

-   本地盘

    包括大数据型的SATA本地盘和本地SSD盘。磁盘直接挂载在计算节点上，性能高于云盘。本地盘不能选择磁盘数量，只能使用默认配置好的数量，数据也没有后端的备份机制，需要上层的软件来保证数据可靠性。


在E-MapReduce集群中，当实例节点释放时，所有云盘和本地盘都会清除数据，磁盘无法独立的保存下来并再次使用。Hadoop HDFS会使用所有的数据盘作为数据存储。 Hadoop YARN也会使用所有的数据盘作为计算的临时存储。

当业务数据量处于TB级别以下时，您可以使用云盘，云盘的IOPS和吞吐相比本地盘都会小些。当数据量处于TB级别以上时，推荐都使用本地盘，本地盘的数据可靠性由E-MapReduce来保证。在使用云盘时，如果吞吐量明显不足，则可以切换为本地盘。

## OSS

在E-MapReduce集群中，您可以将OSS作为HDFS使用。 E-MapReduce可以方便的读写OSS上的数据，所有使用HDFS的代码经过简单的修改即可以访问OSS的数据。例如：

-   Spark读取HDFS中的数据。

    ```
    sc.textfile("hdfs://user/path")
    ```

    更改存储类型为OSS。

    ```
    sc.textfile("oss://user/path")
    ```

-   对于MR或Hive作业也是一样，HDFS命令可直接操作OSS数据，示例如下。

    ```
    hadoop fs -ls oss://bucket/path
    hadoop fs -cp hdfs://user/path  oss://bucket/path
    ```

    此过程中，您不需要输入AccessKey和Endpoint，E-MapReduce会使用当前集群所有者的信息自动补全AccessKey和Endpoint。但OSS的IOPS不高，不适合用在IOPS要求高的场景，例如，流式计算Spark Streaming和HBase。


